# Copyright (c) 2022, Zikang Zhou. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import os
# itertoolsæ˜¯pythonæ ‡å‡†åº“ä¸­çš„ä¸€ä¸ªæ¨¡å—ï¼Œæä¾›ä¸€ç³»åˆ—ç”¨äºç”Ÿæˆå’Œå¤„ç†è¿­ä»£å™¨çš„å‡½æ•°ã€‚
# permutationså‡½æ•°ç”Ÿæˆåºåˆ—çš„æ‰€æœ‰å¯èƒ½çš„æ’åˆ—
from itertools import permutations
# productå‡½æ•°ç”Ÿæˆç¬›å¡å°”ç§¯
from itertools import product
from typing import Callable, Dict, List, Optional, Tuple, Union

import numpy as np
import pandas as pd
import torch
from argoverse.map_representation.map_api import ArgoverseMap
from torch_geometric.data import Data
from torch_geometric.data import Dataset
from tqdm import tqdm

from utils import TemporalData

# è¿™é‡Œç»§æ‰¿çš„æ˜¯geometric.dataä¸­çš„DatasetåŸºç±»ï¼Œç®€å•æ¥è¯´å°±æ˜¯ç”¨äºåˆ›å»ºå›¾æ•°æ®
# è¯¦æƒ…å‚è€ƒï¼šhttps://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Dataset.html#torch_geometric.data.Dataset
class ArgoverseV1Dataset(Dataset):
    # root:æ•°æ®é›†å­˜æ”¾çš„åœ°å€ï¼ˆç›®å½•ï¼‰ã€splitï¼šæŒ‰ç›®çš„åˆ’åˆ†æ•°æ®é›†ã€transformï¼šå¯¹æ•°æ®è¿›è¡Œè½¬æ¢ ï¼Œè½¬æ¢å¯ä»¥ç†è§£ä¸ºå¯¹æ•°æ®çš„æ“ä½œï¼Œå¦‚ç¼©æ”¾scaleä¹‹ç±»ï¼Ÿ  
    def __init__(self,
                 root: str,
                 split: str,
                 transform: Optional[Callable] = None,
                 local_radius: float = 50) -> None:
        self._split = split
        self._local_radius = local_radius
        # ä¸‹åˆ’çº¿å‰ç¼€é€šå¸¸ç”¨äºå°†å±æ€§ä¸ç±»åç§°åŒºåˆ†ï¼Œfä»£è¡¨å°†splitå˜é‡æ’å…¥åˆ°å­—ç¬¦ä¸²ä¸­
        self._url = f'https://s3.amazonaws.com/argoai-argoverse/forecasting_{split}_v1.1.tar.gz'
        if split == 'sample':
            self._directory = 'forecasting_sample'
        elif split == 'train':
            self._directory = 'train'
        elif split == 'val':
            self._directory = 'val'
        elif split == 'test':
            self._directory = 'test_obs'
        else:
            raise ValueError(split + ' is not valid')
        self.root = root
        self._raw_file_names = os.listdir(self.raw_dir)
        # os.path.splitextå‡½æ•°å°†æ–‡ä»¶ååˆ†å‰²ä¸ºä¸¤éƒ¨åˆ†ï¼Œå‰éƒ¨åˆ†æ˜¯æ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰ï¼Œåéƒ¨åˆ†æ˜¯æ‰©å±•å
        self._processed_file_names = [os.path.splitext(f)[0] + '.pt' for f in self.raw_file_names]
        # å°†ä¸Šä¸€å¥å¾—åˆ°çš„æ–‡ä»¶å­˜å…¥åˆ°processed_dirä¸­ï¼Œprocessed_dirçš„å®šä¹‰åœ¨ä¸‹æ–¹æœ‰è¯´æ˜ = os.path.join(self.root,self._directory,'processed')
        self._processed_paths = [os.path.join(self.processed_dir, f) for f in self._processed_file_names]
        super(ArgoverseV1Dataset, self).__init__(root, transform=transform)

    # @propertyæ˜¯pythonçš„ä¸€ä¸ªè£…é¥°å™¨ï¼Œç”¨äºå°†ä¸€ä¸ªæ–¹æ³•è½¬ä¸ºå±æ€§ï¼Œå±æ€§æ˜¯ç±»çš„ä¸€ä¸ªæˆå‘˜ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡ç±»åè®¿é—®ï¼Œè€Œä¸éœ€è¦ä½¿ç”¨ç‚¹ï¼ˆ.ï¼‰è¿ç®—ç¬¦
    @property
    def raw_dir(self) -> str:
        return os.path.join(self.root, self._directory, 'data')

    @property
    def processed_dir(self) -> str:
        return os.path.join(self.root, self._directory, 'processed')

    # Unionæ˜¯ä¸€ä¸ªç±»å‹æ³¨é‡Šï¼Œç”¨äºæŒ‡å®šä¸€ä¸ªç±»å‹çš„å˜é‡å¯ä»¥å…·æœ‰å¤šä¸ªå¯èƒ½çš„ç±»å‹ã€‚åœ¨æ­¤å¤„ï¼Œraw_file_namesæ–¹æ³•çš„è¿”å›å€¼å¯ä»¥æ˜¯strã€List[str]ã€Tuple
    @property
    def raw_file_names(self) -> Union[str, List[str], Tuple]:
        return self._raw_file_names

    @property
    def processed_file_names(self) -> Union[str, List[str], Tuple]:
        return self._processed_file_names

    @property
    def processed_paths(self) -> List[str]:
        return self._processed_paths

    def process(self) -> None:
        am = ArgoverseMap()
        # å¯¹æ¯ä¸ªæ–‡ä»¶è¿›è¡Œå¤„ç†
        for raw_path in tqdm(self.raw_paths):
            kwargs = process_argoverse(self._split, raw_path, am, self._local_radius)
            data = TemporalData(**kwargs)
            torch.save(data, os.path.join(self.processed_dir, str(kwargs['seq_id']) + '.pt'))

    def len(self) -> int:
        return len(self._raw_file_names)

    def get(self, idx) -> Data:
        return torch.load(self.processed_paths[idx])


def process_argoverse(split: str,
                      raw_path: str,
                      am: ArgoverseMap,
                      radius: float) -> Dict:
    # ä»raw_pathä¸­è¯»å–csvæ–‡ä»¶
    df = pd.read_csv(raw_path)

    # filter out actors that are unseen during the historical time stepsï¼Œå»é™¤æ‰é‚£äº›åœ¨è§‚æµ‹æ—¶é—´å†…ä¸å¯è§çš„è½¦è¾†
    timestamps = list(np.sort(df['TIMESTAMP'].unique()))
    historical_timestamps = timestamps[: 20]
    # isinæ˜¯pythonä¸­çš„ä¸€ä¸ªå†…ç½®æ–¹æ³•ï¼Œç”¨äºæ£€æŸ¥ä¸€ä¸ªæ•°ç»„ä¸­çš„å…ƒç´ æ˜¯å¦å­˜åœ¨äºå¦ä¸€ä¸ªæ•°ç»„ä¸­
    historical_df = df[df['TIMESTAMP'].isin(historical_timestamps)]
    # è·å–è§‚æµ‹æ—¶é—´å†…å¯¹åº”çš„è½¦è¾†IDä¿¡æ¯
    actor_ids = list(historical_df['TRACK_ID'].unique())
    df = df[df['TRACK_ID'].isin(actor_ids)]
    # ç»Ÿè®¡è§‚æµ‹æ—¶é—´å†…è½¦è¾†çš„æ•°ç›®
    num_nodes = len(actor_ids)

    # AVæ˜¯argoverseæ•°æ®é›†ä¸­å¯¹è‡ªè½¦çš„æ ‡ç­¾
    av_df = df[df['OBJECT_TYPE'] == 'AV'].iloc
    av_index = actor_ids.index(av_df[0]['TRACK_ID'])
    # AGENTæ˜¯argoverseæ•°æ®é›†ä¸­å¯¹ç›®æ ‡æ™ºèƒ½ä½“çš„æ ‡ç­¾
    agent_df = df[df['OBJECT_TYPE'] == 'AGENT'].iloc
    agent_index = actor_ids.index(agent_df[0]['TRACK_ID'])
    city = df['CITY_NAME'].values[0]

    # make the scene centered at AVï¼Œè®©åœºæ™¯ä»¥è‡ªè½¦ä¸ºä¸­å¿ƒ
    origin = torch.tensor([av_df[19]['X'], av_df[19]['Y']], dtype=torch.float)
    # è‡ªè½¦çš„èˆªå‘çŸ¢é‡
    av_heading_vector = origin - torch.tensor([av_df[18]['X'], av_df[18]['Y']], dtype=torch.float)
    # èˆªå‘è§’
    theta = torch.atan2(av_heading_vector[1], av_heading_vector[0])
    # ä½¿ç”¨è‡ªè½¦èˆªå‘è§’å‚æ•°åŒ–çš„æ—‹è½¬çŸ©é˜µ
    rotate_mat = torch.tensor([[torch.cos(theta), -torch.sin(theta)],
                               [torch.sin(theta), torch.cos(theta)]])

    # initialization
    # åˆå§‹åŒ–xï¼Œnum_nodesæ˜¯è½¦è¾†æ€»æ•°ï¼Œ50æ˜¯è§‚æµ‹æ—¶é—´+é¢„æµ‹æ—¶é—´å¯¹åº”çš„ç‚¹æ•°ï¼ˆ10hzï¼‰ï¼Œ2æ˜¯å¯¹åº”è½¦è¾†xyåæ ‡å€¼
    x = torch.zeros(num_nodes, 50, 2, dtype=torch.float)
    '''
    è¾¹çš„ç´¢å¼•ï¼Œpermutationç”¨äºç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„è¾¹ï¼ˆåœ¨æ‰€æœ‰èŠ‚ç‚¹æ•°ä¹‹é—´ä¸¤ä¸¤ç»„åˆï¼‰ï¼Œpermutationæ–¹æ³•è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰å¯èƒ½è¾¹çš„åˆ—è¡¨ï¼Œç„¶ålistå°†å…¶è½¬åŒ–ä¸ºpythonçš„åˆ—è¡¨ç±»å‹ï¼Œç„¶åtorchå†å°†å…¶è½¬ä¸ºLongTensorå¼ é‡ï¼›
    t().contiguous()æ–¹æ³•å°†å¼ é‡çš„å½¢çŠ¶è½¬ä¸ºï¼ˆ2ï¼Œnum_edgesï¼‰ï¼Œå…¶ä¸­num_edgesæ˜¯è¾¹çš„æ•°é‡ï¼›
    å…·ä½“å½¢çŠ¶å¯ä»¥è¯•ç€è‡ªå·±æ‰“å°ä¸€ä¸‹ã€‚æ‰“å°å‡ºæ¥ï¼Œå‘ç°è¿™ä¸ªè¾¹çš„è¡¨è¿°å…¶å®ç±»ä¼¼äºsparse COO formatã€‚belikeğŸ‘‡ (è¿™é‡Œæ˜¯å–äº†num_nodes=5)
    tensro([[0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4],
            [1,2,3,4,0,2,3,4,0,1,3,4,0,1,2,4,0,1,2,3]])
    '''
    edge_index = torch.LongTensor(list(permutations(range(num_nodes), 2))).t().contiguous()
    # åˆ›å»ºç›¸å…³maskå’Œæ—‹è½¬è§’çš„çŸ©é˜µ
    padding_mask = torch.ones(num_nodes, 50, dtype=torch.bool) # åˆ›å»ºåˆå§‹éƒ½æ˜¯true
    bos_mask = torch.zeros(num_nodes, 20, dtype=torch.bool)
    rotate_angles = torch.zeros(num_nodes, dtype=torch.float)

    # æŒ‰ç…§æŒ‡å®šçš„åˆ—è¿›è¡Œåˆ†ç»„ï¼Œè¿™é‡ŒæŒ‰â€˜TRACK_IDâ€™åˆ’åˆ†
    for actor_id, actor_df in df.groupby('TRACK_ID'):
        node_idx = actor_ids.index(actor_id)
        node_steps = [timestamps.index(timestamp) for timestamp in actor_df['TIMESTAMP']]
        padding_mask[node_idx, node_steps] = False
        if padding_mask[node_idx, 19]:  # make no predictions for actors that are unseen at the current time step
            padding_mask[node_idx, 20:] = True
        # è·å–è½¦è¾†çš„xyåæ ‡ä¿¡æ¯
        xy = torch.from_numpy(np.stack([actor_df['X'].values, actor_df['Y'].values], axis=-1)).float()
        # xy-origin å³ä»ç»å¯¹åæ ‡è½¬æˆç›¸å¯¹åæ ‡ï¼ˆç›¸å¯¹è‡ªè½¦çš„originæ—¶åˆ»ï¼Œå³è§‚æµ‹æ—¶é—´æœ«æ—¶åˆ»ï¼‰ï¼Œå†ä¸æ—‹è½¬çŸ©é˜µç›¸ä¹˜ï¼Œå¾—åˆ°ä»¥è§‚æµ‹æ—¶é—´æœ«æ—¶åˆ»ä¸ºä¸­å¿ƒçš„åæ ‡ç³»ä¸‹çš„å€¼
        x[node_idx, node_steps] = torch.matmul(xy - origin, rotate_mat)
        node_historical_steps = list(filter(lambda node_step: node_step < 20, node_steps))
        if len(node_historical_steps) > 1:  # calculate the heading of the actor (approximately) ç›¸å½“äºå¯¹é™¤è‡ªè½¦ä»¥å¤–çš„å…¶å®ƒè½¦çš„èˆªå‘çŸ¢é‡å’Œæ—‹è½¬è§’è¿›è¡Œæ›´æ–°ï¼Ÿ
            heading_vector = x[node_idx, node_historical_steps[-1]] - x[node_idx, node_historical_steps[-2]]
            rotate_angles[node_idx] = torch.atan2(heading_vector[1], heading_vector[0])
        else:  # make no predictions for the actor if the number of valid time steps is less than 2
            padding_mask[node_idx, 20:] = True

    # bos_mask is True if time step t is valid and time step t-1 is invalid
    bos_mask[:, 0] = ~padding_mask[:, 0]
    bos_mask[:, 1: 20] = padding_mask[:, : 19] & ~padding_mask[:, 1: 20]

    positions = x.clone()
    x[:, 20:] = torch.where((padding_mask[:, 19].unsqueeze(-1) | padding_mask[:, 20:]).unsqueeze(-1),
                            torch.zeros(num_nodes, 30, 2),
                            x[:, 20:] - x[:, 19].unsqueeze(-2))
    x[:, 1: 20] = torch.where((padding_mask[:, : 19] | padding_mask[:, 1: 20]).unsqueeze(-1),
                              torch.zeros(num_nodes, 19, 2),
                              x[:, 1: 20] - x[:, : 19])
    x[:, 0] = torch.zeros(num_nodes, 2)

    # get lane features at the current time step
    df_19 = df[df['TIMESTAMP'] == timestamps[19]]
    node_inds_19 = [actor_ids.index(actor_id) for actor_id in df_19['TRACK_ID']]
    node_positions_19 = torch.from_numpy(np.stack([df_19['X'].values, df_19['Y'].values], axis=-1)).float()
    (lane_vectors, is_intersections, turn_directions, traffic_controls, lane_actor_index,
     lane_actor_vectors) = get_lane_features(am, node_inds_19, node_positions_19, origin, rotate_mat, city, radius)

    y = None if split == 'test' else x[:, 20:]
    seq_id = os.path.splitext(os.path.basename(raw_path))[0]

    return {
        'x': x[:, : 20],  # [N, 20, 2]
        'positions': positions,  # [N, 50, 2]
        'edge_index': edge_index,  # [2, N x N - 1]
        'y': y,  # [N, 30, 2]
        'num_nodes': num_nodes,
        'padding_mask': padding_mask,  # [N, 50]
        'bos_mask': bos_mask,  # [N, 20]
        'rotate_angles': rotate_angles,  # [N]
        'lane_vectors': lane_vectors,  # [L, 2]
        'is_intersections': is_intersections,  # [L]
        'turn_directions': turn_directions,  # [L]
        'traffic_controls': traffic_controls,  # [L]
        'lane_actor_index': lane_actor_index,  # [2, E_{A-L}]
        'lane_actor_vectors': lane_actor_vectors,  # [E_{A-L}, 2]
        'seq_id': int(seq_id),
        'av_index': av_index,
        'agent_index': agent_index,
        'city': city,
        'origin': origin.unsqueeze(0),
        'theta': theta,
    }


def get_lane_features(am: ArgoverseMap,
                      node_inds: List[int],
                      node_positions: torch.Tensor,
                      origin: torch.Tensor,
                      rotate_mat: torch.Tensor,
                      city: str,
                      radius: float) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor,
                                              torch.Tensor]:
    lane_positions, lane_vectors, is_intersections, turn_directions, traffic_controls = [], [], [], [], []
    lane_ids = set()
    for node_position in node_positions:
        lane_ids.update(am.get_lane_ids_in_xy_bbox(node_position[0], node_position[1], city, radius))
    node_positions = torch.matmul(node_positions - origin, rotate_mat).float()
    for lane_id in lane_ids:
        lane_centerline = torch.from_numpy(am.get_lane_segment_centerline(lane_id, city)[:, : 2]).float()
        lane_centerline = torch.matmul(lane_centerline - origin, rotate_mat)
        is_intersection = am.lane_is_in_intersection(lane_id, city)
        turn_direction = am.get_lane_turn_direction(lane_id, city)
        traffic_control = am.lane_has_traffic_control_measure(lane_id, city)
        lane_positions.append(lane_centerline[:-1])
        lane_vectors.append(lane_centerline[1:] - lane_centerline[:-1])
        count = len(lane_centerline) - 1
        is_intersections.append(is_intersection * torch.ones(count, dtype=torch.uint8))
        if turn_direction == 'NONE':
            turn_direction = 0
        elif turn_direction == 'LEFT':
            turn_direction = 1
        elif turn_direction == 'RIGHT':
            turn_direction = 2
        else:
            raise ValueError('turn direction is not valid')
        turn_directions.append(turn_direction * torch.ones(count, dtype=torch.uint8))
        traffic_controls.append(traffic_control * torch.ones(count, dtype=torch.uint8))
    lane_positions = torch.cat(lane_positions, dim=0)
    lane_vectors = torch.cat(lane_vectors, dim=0)
    is_intersections = torch.cat(is_intersections, dim=0)
    turn_directions = torch.cat(turn_directions, dim=0)
    traffic_controls = torch.cat(traffic_controls, dim=0)

    lane_actor_index = torch.LongTensor(list(product(torch.arange(lane_vectors.size(0)), node_inds))).t().contiguous()
    lane_actor_vectors = \
        lane_positions.repeat_interleave(len(node_inds), dim=0) - node_positions.repeat(lane_vectors.size(0), 1)
    mask = torch.norm(lane_actor_vectors, p=2, dim=-1) < radius
    lane_actor_index = lane_actor_index[:, mask]
    lane_actor_vectors = lane_actor_vectors[mask]

    return lane_vectors, is_intersections, turn_directions, traffic_controls, lane_actor_index, lane_actor_vectors
